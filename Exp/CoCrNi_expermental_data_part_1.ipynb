{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qohh3Yyymycs",
        "outputId": "6f618046-544d-4ef5-95d7-0c6afb96072e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks/CoCrNi_experiment\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/Colab Notebooks/CoCrNi_experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fast_histogram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayLr5fyBnuti",
        "outputId": "f226a114-8c99-4ed5-bb73-fc3fb59035b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fast_histogram\n",
            "  Downloading fast_histogram-0.11-cp36-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m550.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fast_histogram) (1.22.4)\n",
            "Installing collected packages: fast_histogram\n",
            "Successfully installed fast_histogram-0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "import multiprocessing as mp\n",
        "import shutil\n",
        "from itertools import product\n",
        "import psutil\n",
        "n_phys_cores=psutil.cpu_count(logical=False)\n",
        "\n",
        "# custom modules\n",
        "import zsdm_utils_v2 as zsdm_utils\n",
        "# import datasphere.populate as dsp\n"
      ],
      "metadata": {
        "id": "PpV0u1Jsc0aa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder = os.path.join(os.getcwd(), 'data')\n",
        "csv_paths = zsdm_utils.get_csv_paths(folder)\n",
        "data = pd.read_csv(csv_paths[0],\n",
        "                   names=['x', 'y', 'z', 'Da'])\n",
        "#print(data)\n",
        "rrange_file = 'R5096_71247_100.RRNG'\n",
        "ions, rrngs = zsdm_utils.read_rrng(rrange_file)\n",
        "#print(rrngs)"
      ],
      "metadata": {
        "id": "E66-yBglc9EG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pls type me\n",
        "element_1_name = 'Co'\n",
        "element_2_name = 'Cr'\n",
        "element_3_name = 'Ni'\n",
        "element_1_range = rrngs[rrngs['comp']==element_1_name+':1']\n",
        "element_2_range = rrngs[rrngs['comp']==element_2_name+':1']\n",
        "element_3_range = rrngs[rrngs['comp']==element_3_name+':1']\n",
        "#print(element_1_range)\n",
        "#print(element_2_range)\n",
        "\n",
        "element_1 = zsdm_utils.atom_filter(data, element_1_range)\n",
        "element_2 = zsdm_utils.atom_filter(data, element_2_range)\n",
        "element_3 = zsdm_utils.atom_filter(data, element_3_range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSNBmGGAltZQ",
        "outputId": "7517e44b-af70-4a59-8996-c76de97bd783"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATOM TOTAL = 451319\n",
            "ATOM TOTAL = 497758\n",
            "ATOM TOTAL = 428632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/CoCrNi_experiment/zsdm_utils_v2.py:82: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  x['Da'].between(Atom_range['lower'][i], Atom_range['upper'][i], inclusive=True)\n",
            "/content/gdrive/MyDrive/Colab Notebooks/CoCrNi_experiment/zsdm_utils_v2.py:82: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  x['Da'].between(Atom_range['lower'][i], Atom_range['upper'][i], inclusive=True)\n",
            "/content/gdrive/MyDrive/Colab Notebooks/CoCrNi_experiment/zsdm_utils_v2.py:82: FutureWarning: Boolean inputs to the `inclusive` argument are deprecated in favour of `both` or `neither`.\n",
            "  x['Da'].between(Atom_range['lower'][i], Atom_range['upper'][i], inclusive=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_min = data.min()\n",
        "data_max = data.max()\n",
        "\n",
        "#print(data_min)\n",
        "#print(data_max)\n",
        "data_min['c'], data_min['b'], data_min['a'] = -120, -10, -10  #nm\n",
        "data_max['c'], data_max['b'], data_max['a'] = 0, 10, 10   #nm\n",
        "\n",
        "# scanning parameters \n",
        "voxel = np.array([1.0],dtype=np.float64)\n",
        "#print(\"voxel shape {}\".format(voxel.shape))\n",
        "stride = 0.5"
      ],
      "metadata": {
        "id": "Orn3x-zwl-DZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%Paralell to get data sphere points\n",
        "# data_Z_list = np.arange(int(data_min['c']), int(data_max['c']), stride,dtype=np.float64)\n",
        "# #print(\"data Z list shape {}\".format(data_Z_list.shape))\n",
        "# data_Y_list = np.arange(int(data_min['b']), int(data_max['b']), stride,dtype=np.float64)\n",
        "# data_X_list = np.arange(int(data_min['a']), int(data_max['a']), stride,dtype=np.float64)\n",
        "# #print(\"LEN Z Y X lists {} {} {}\".format(len(data_Z_list), len(data_Y_list), len(data_X_list)))\n",
        "# ZZ=zsdm_utils.low_pass_filter(data_Z_list, data_max['c']-voxel) # can be improved\n",
        "# #print(\"ZZ list shape {}\".format(ZZ.shape))\n",
        "# YY=zsdm_utils.low_pass_filter(data_Y_list, data_max['b']-voxel)\n",
        "# XX=zsdm_utils.low_pass_filter(data_X_list, data_max['a']-voxel)\n",
        "# print(\"LEN Z Y X lists {} {} {}\".format(len(ZZ), len(YY), len(XX)))\n",
        "\n",
        "# Nrows = ZZ.size * YY.size * XX.size\n",
        "# data_sphere_points=dsp.init_data_sphere(XX,YY,ZZ,voxel)\n",
        "# data_sphere_points[:, [0, 2]] = data_sphere_points[:, [2, 0]]\n",
        "# #print(\"data sphere points\")\n",
        "# # print(data_sphere_points[0:80,])\n",
        "# # print(data_sphere_points[-2,])\n",
        "# np.save (\"data_sphere_points_cocrni.npy\", data_sphere_points)\n",
        "# data_sphere_points = np.load(\"data_sphere_points_cocrni.npy\")"
      ],
      "metadata": {
        "id": "HV1k4Q4rmScU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%Building sphere heart array\n",
        "try:\n",
        "  data_sphere_points = np.load(\"data_sphere_points_cocrni_1_1.npy\")\n",
        "except:\n",
        "  data_Z_list = list(np.arange(int(data_min['c']), int(data_max['c']), stride))\n",
        "  data_Y_list = list(np.arange(int(data_min['b']), int(data_max['b']), stride))\n",
        "  data_X_list = list(np.arange(int(data_min['a']), int(data_max['a']), stride))\n",
        "  data_sphere_points = np.zeros((1,3))\n",
        "  for data_Z, data_Y, data_X in product(data_Z_list, data_Y_list, data_X_list):\n",
        "      if data_Z+voxel > data_max['c'] or data_Y+voxel > data_max['b'] or data_X+voxel > data_max['a']:\n",
        "          continue\n",
        "      else:\n",
        "          temp = np.array([data_X+voxel/2, data_Y+voxel/2, data_Z+voxel/2]).reshape((1,3)) \n",
        "          data_sphere_points = np.concatenate((data_sphere_points, temp), axis=0)\n",
        "  data_sphere_points = data_sphere_points[1:]\n",
        "  np.save (\"data_sphere_points_cocrni.npy\", data_sphere_points)"
      ],
      "metadata": {
        "id": "uRp-UNMOmg_4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "zSDMs of voxelized (1x1x1 with 0.5 stride) experimental data"
      ],
      "metadata": {
        "id": "9MPWujv4F1t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npy_filenames=[\n",
        "      \"\".join([\"zSDM_exp_test_\"+element_1_name+element_1_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "      \"\".join([\"zSDM_exp_test_\"+element_2_name+element_2_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "      \"\".join([\"zSDM_exp_test_\"+element_3_name+element_3_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"])]\n",
        "\n",
        "#ZSDMs\n",
        "# try:\n",
        "#   np.load(npy_filenames[0])\n",
        "#   np.load(npy_filenames[1])\n",
        "#   np.load(npy_filenames[2])\n",
        "# except:\n",
        "items_test = ['element_1', 'element_2', 'element_3']\n",
        "from itertools import combinations\n",
        "for chosen in combinations(items_test, 1):\n",
        "  print(chosen[0])\n",
        "\n",
        "items = [element_1.values, element_2.values, element_3.values]\n",
        "# items = [df_1_new_element_2.values, df_1_new_element_3.values]\n",
        "from itertools import combinations\n",
        "num = 0\n",
        "for chosen in combinations(items, 1):\n",
        "  print('Cycle is', num)\n",
        "  element_chosen_1, element_chosen_2= chosen[0], chosen[0]\n",
        "  print(element_chosen_1, element_chosen_2)\n",
        "  #element_chosen_1, element_chosen_2 = element_1.values, element_2.values\n",
        "  tree_1 = cKDTree(element_chosen_1)\n",
        "  tree_2 = cKDTree(element_chosen_2)\n",
        "  # tree_3 = cKDTree(element_chosen_3)\n",
        "  index_voxel_sphere_1 = tree_1.query_ball_point(data_sphere_points, voxel[0]*1.5/2)\n",
        "  index_voxel_sphere_2 = tree_2.query_ball_point(data_sphere_points, voxel[0]*1.5/2)\n",
        "  # index_voxel_sphere_3 = tree_3.query_ball_point(data_sphere_points, voxel[0]/2)\n",
        "  #print(type(index_voxel_sphere))\n",
        "  #print(type(index_voxel_sphere[0]))\n",
        "\n",
        "  ZSDM_partial=partial(zsdm_utils.zsdm,\n",
        "                      element_chosen_1 = element_chosen_1,\n",
        "                      element_chosen_2 = element_chosen_2,\n",
        "                      index_voxel_sphere_1 = index_voxel_sphere_1,\n",
        "                      index_voxel_sphere_2 = index_voxel_sphere_2)\n",
        "\n",
        "  print(\"starting parallel pool\")\n",
        "  with mp.Pool(processes=n_phys_cores) as pool:\n",
        "      zSDM_output=pool.map(ZSDM_partial, range(len(data_sphere_points)))\n",
        "  print(\"done parallel pool\")\n",
        "\n",
        "  #zSDM save\n",
        "  #print(npy_filenames)\n",
        "  #print(len(npy_filenames))\n",
        "  zsdm_utils.ndarray2npy(zSDM_output, npy_filenames[num])\n",
        "  num = num+1"
      ],
      "metadata": {
        "id": "2sjqlltfslV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c53ce2-82e5-4e59-bfcf-d1b7b34ad23c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "element_1\n",
            "element_2\n",
            "element_3\n",
            "Cycle is 0\n",
            "[[-9.278779e-01  3.823761e+00 -2.764258e-01]\n",
            " [-1.007992e+00 -2.922290e+00 -1.710485e-01]\n",
            " [-2.881494e-01 -2.125227e+00 -8.312608e-02]\n",
            " ...\n",
            " [ 7.866820e+00 -1.062481e+00 -1.187137e+02]\n",
            " [ 7.586777e+00 -9.620218e+00 -1.194045e+02]\n",
            " [-6.043423e+00  8.195497e+00 -1.190356e+02]] [[-9.278779e-01  3.823761e+00 -2.764258e-01]\n",
            " [-1.007992e+00 -2.922290e+00 -1.710485e-01]\n",
            " [-2.881494e-01 -2.125227e+00 -8.312608e-02]\n",
            " ...\n",
            " [ 7.866820e+00 -1.062481e+00 -1.187137e+02]\n",
            " [ 7.586777e+00 -9.620218e+00 -1.194045e+02]\n",
            " [-6.043423e+00  8.195497e+00 -1.190356e+02]]\n",
            "starting parallel pool\n",
            "done parallel pool\n",
            "Saving np array into zSDM_exp_test_CoCo_-120_0_10_10_1_0.5.npy...\n",
            "Done.\n",
            "Cycle is 1\n",
            "[[-1.518460e+00  2.967626e+00 -1.991419e-01]\n",
            " [-1.570879e+00  1.190667e+00 -7.090725e-02]\n",
            " [ 2.688860e+00 -4.287879e+00 -4.609191e-01]\n",
            " ...\n",
            " [-6.175797e+00 -5.512067e+00 -1.187572e+02]\n",
            " [ 9.120081e+00 -7.445741e+00 -1.193130e+02]\n",
            " [ 3.241909e+00 -1.088100e+01 -1.192358e+02]] [[-1.518460e+00  2.967626e+00 -1.991419e-01]\n",
            " [-1.570879e+00  1.190667e+00 -7.090725e-02]\n",
            " [ 2.688860e+00 -4.287879e+00 -4.609191e-01]\n",
            " ...\n",
            " [-6.175797e+00 -5.512067e+00 -1.187572e+02]\n",
            " [ 9.120081e+00 -7.445741e+00 -1.193130e+02]\n",
            " [ 3.241909e+00 -1.088100e+01 -1.192358e+02]]\n",
            "starting parallel pool\n",
            "done parallel pool\n",
            "Saving np array into zSDM_exp_test_CrCr_-120_0_10_10_1_0.5.npy...\n",
            "Done.\n",
            "Cycle is 2\n",
            "[[-3.268559e+00  3.123968e+00 -3.658291e-01]\n",
            " [-1.403513e+00 -1.890022e+00 -9.914255e-02]\n",
            " [-2.144952e+00 -4.123662e+00 -3.880529e-01]\n",
            " ...\n",
            " [-4.441107e+00 -8.501245e+00 -1.189426e+02]\n",
            " [-2.980980e+00  8.106631e+00 -1.188051e+02]\n",
            " [ 7.209991e+00 -4.992392e+00 -1.188234e+02]] [[-3.268559e+00  3.123968e+00 -3.658291e-01]\n",
            " [-1.403513e+00 -1.890022e+00 -9.914255e-02]\n",
            " [-2.144952e+00 -4.123662e+00 -3.880529e-01]\n",
            " ...\n",
            " [-4.441107e+00 -8.501245e+00 -1.189426e+02]\n",
            " [-2.980980e+00  8.106631e+00 -1.188051e+02]\n",
            " [ 7.209991e+00 -4.992392e+00 -1.188234e+02]]\n",
            "starting parallel pool\n",
            "done parallel pool\n",
            "Saving np array into zSDM_exp_test_NiNi_-120_0_10_10_1_0.5.npy...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experimental data preprocessing"
      ],
      "metadata": {
        "id": "nNWndAO-Fnyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Data preprocessing\n",
        "npy_filenames_preprocess=[\n",
        "    \"\".join([\"nzSDM_exp_preprocessing_2_\"+element_1_name+element_1_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "    \"\".join([\"nzSDM_exp_preprocessing_2_\"+element_2_name+element_2_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "    \"\".join([\"nzSDM_exp_preprocessing_2_\"+element_3_name+element_3_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"])]\n",
        "\n",
        "npy_filenames_prediction=[\n",
        "    \"\".join([\"CoCrNi_test_data_\"+element_1_name+element_1_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "    \"\".join([\"CoCrNi_test_data_\"+element_2_name+element_2_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"]),\n",
        "    \"\".join([\"CoCrNi_test_data_\"+element_3_name+element_3_name+\"_\",str(int(data_min['c'])),\"_\",str(int(data_max['c'])),\"_10_10_1_0.5.npy\"])]\n",
        "# import tensorflow as tf\n",
        "\n",
        "for element_chosen in range(3):\n",
        "    print(element_chosen)\n",
        "    # if element_chosen==0 or element_chosen==1:\n",
        "    #   continue\n",
        "    # else:\n",
        "    zSDM_exp_element_1 = np.load(npy_filenames[element_chosen])\n",
        "    # zSDM_exp_element_2 = np.load(npy_filenames[1])\n",
        "    # zSDM_exp_element_3 = np.load(test_dir+\"zSDM_exp_test_\"+element_3_name+element_3_name+\"_%s_%s_%s_%s_%s_%s.npy\"\n",
        "    #               %(int(data_min['c']), int(data_max['c']), int(data_max['b']), int(data_max['a']), voxel, stride) )            \n",
        "\n",
        "    dim = zSDM_exp_element_1.shape[0]*zSDM_exp_element_1.shape[2]\n",
        "    zSDM_exp_element_1_2d = np.reshape(np.transpose(zSDM_exp_element_1,(1,0,2)),(-1, dim))\n",
        "    # zSDM_exp_element_2_2d = np.reshape(np.transpose(zSDM_exp_element_2,(1,0,2)),(-1, dim))\n",
        "    # zSDM_exp_element_3_2d = np.reshape(np.transpose(zSDM_exp_element_3,(1,0,2)),(-1, dim))\n",
        "    # Data normalization\n",
        "    nzSDM_exp_element_1 = zsdm_utils.normdata(zSDM_exp_element_1_2d)\n",
        "    # nzSDM_exp_element_2 = normdata(zSDM_exp_element_2_2d)\n",
        "    # nzSDM_exp_element_3 = normdata(zSDM_exp_element_3_2d)\n",
        "\n",
        "    nzSDM_exp= nzSDM_exp_element_1 #revised into three elements\n",
        "    save_newexpZSDMs = False\n",
        "    # Build ouptfile\n",
        "    if save_newexpZSDMs == True:\n",
        "        try:\n",
        "            shutil.rmtree('Results_newexpZSDMs_'+element_1_name)\n",
        "        except:\n",
        "            print(\"file does not exist\")\n",
        "        os.mkdir('Results_newexpZSDMs_'+element_1_name)\n",
        "\n",
        "    (len1,w1) = np.shape(nzSDM_exp)\n",
        "\n",
        "    preprocessing_partial=partial(zsdm_utils.exp_data_processing_parallel,\n",
        "                            len1=len1, \n",
        "                            nzSDM_exp=nzSDM_exp, \n",
        "                            save_newexpZSDMs=save_newexpZSDMs, \n",
        "                            zSDM_exp_element_1_2d=zSDM_exp_element_1_2d, \n",
        "                            element_1_name=element_1_name)\n",
        "\n",
        "    print(\"starting parallel pool\")\n",
        "    with mp.Pool(processes=n_phys_cores) as pool:\n",
        "        nzSDM_exp_preprocessing_parallel_2=pool.map(preprocessing_partial, range(w1))\n",
        "    print(\"done parallel pool\")\n",
        "    zsdm_utils.ndarray2npy(nzSDM_exp_preprocessing_parallel_2, npy_filenames_preprocess[element_chosen])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "ZXRaHLm9Exkj",
        "outputId": "fd3cb48f-cb58-4e11-ae60-addf57644d76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-46d2e9995baf>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    x_exp = np.reshape(nzSDM_exp_preprocessing_parallel_2, (w1, len1))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}